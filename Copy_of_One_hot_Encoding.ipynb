{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/will-mccormack/CS-M148-Proj/blob/main/Copy_of_One_hot_Encoding.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GE_Xj6VnmjzD"
      },
      "source": [
        "This file is the code used to split the dataset and download it into a 60-20-20 split for training, validation, and testing. The data files will be saved on github so all group are working on the same splits. Additionally, a seed (28) was indicated/used so that the same split can be obtained even if access to the saved files is not available."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2Y2caSSTmjzG"
      },
      "outputs": [],
      "source": [
        "%pip install datasets"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "plt.style.use('seaborn-v0_8-whitegrid')"
      ],
      "metadata": {
        "id": "YWjLCVTJsG5a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y6Ms7qCFmjzI"
      },
      "outputs": [],
      "source": [
        "from datasets import load_dataset\n",
        "\n",
        "# Example: IMDb dataset for sentiment classification\n",
        "data = load_dataset(\"maharshipandya/spotify-tracks-dataset\")\n",
        "\n",
        "dataset = data[\"train\"]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pJ9czOtGmjzJ"
      },
      "source": [
        "After loading in the dataset, we split it first into 60-40, with 60 being the train dataset. Then we split the 40 into 20-20 for validation and testing datasets. We are doing 60-20-20 because this seems like a standard split as described in class, and there doesn't seem to be any special features to our dataset that would warrent a differnet split ratio. Additonally, we are splitting by random sample instead of by any set value like date or song length. We are doing this to ensyre that our data is not skewed in the testing or training set, which could inadvertently lead to our model overfitting to our training dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6GT37Oj6mjzK"
      },
      "outputs": [],
      "source": [
        "split_1 = dataset.train_test_split(test_size=0.4, seed = 28)\n",
        "\n",
        "split_2 = split_1[\"test\"].train_test_split(test_size=0.5, seed = 28)\n",
        "\n",
        "train_dataset = split_1[\"train\"]\n",
        "validation_dataset = split_2[\"train\"]\n",
        "test_dataset = split_2[\"test\"]\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qFNSQkSXmjzK"
      },
      "outputs": [],
      "source": [
        "train_dataset.to_csv(\"train.csv\", index=False)\n",
        "validation_dataset.to_csv(\"validation.csv\", index=False)\n",
        "test_dataset.to_csv(\"test.csv\", index=False)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8bfd71cd"
      },
      "source": [
        "train_df = pd.read_csv('train.csv', encoding='utf-8-sig')\n",
        "train_df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e1702462"
      },
      "source": [
        "#One-hot encode genres\n",
        "train_df_encoded = pd.get_dummies(train_df, columns=['track_genre'], prefix='genre')\n",
        "display(train_df_encoded.head())"
      ],
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.6"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}